{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "120150d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:58:22.668055Z",
     "start_time": "2025-06-05T15:58:18.402178Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the JSON files\n",
    "ekg_dir = 'ekg_files'\n",
    "\n",
    "# List to store all DataFrames\n",
    "dfs = []\n",
    "for filename in os.listdir(ekg_dir):\n",
    "    if filename.endswith('.json'):\n",
    "        with open(os.path.join(ekg_dir, filename), 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        # Take the first lead (usually \"I\")\n",
    "        if 'leads' in data and len(data['leads']) > 0:\n",
    "            lead = data['leads'][0]\n",
    "            signal = lead.get('signal', [])\n",
    "            # Remove None values from the signal\n",
    "            clean_signal = [x for x in signal if x is not None]\n",
    "            df_tmp = pd.DataFrame({'Signal': clean_signal})\n",
    "            dfs.append([filename.replace('_','/').replace('.json',''), df_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b202aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:58:22.684549Z",
     "start_time": "2025-06-05T15:58:22.668055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest signal is from 39879/2021 with length 761\n"
     ]
    }
   ],
   "source": [
    "min_length = float('inf')\n",
    "min_kg = None\n",
    "for kg, signal_df in dfs:\n",
    "    if len(signal_df) < min_length:\n",
    "        min_length = len(signal_df)\n",
    "        min_kg = kg\n",
    "        \n",
    "print(f\"Shortest signal is from {min_kg} with length {min_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4065c0f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:58:22.731801Z",
     "start_time": "2025-06-05T15:58:22.686650Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('DANE_mpsi.csv', sep='\\t', encoding='utf-8')\n",
    "\n",
    "# Extract labels from Dane MPSI (df['zgon']) and join with signals from dfs using filename and KG\n",
    "\n",
    "# Prepare a mapping from KG to label\n",
    "kg_to_label = dict(zip(df['KG'], df['zgon']))\n",
    "\n",
    "# Prepare dataset: list of (signal, label) tuples\n",
    "signal_label_dataset = []\n",
    "for kg, signal_df in dfs:\n",
    "    if kg in kg_to_label:\n",
    "        label = kg_to_label[kg]\n",
    "        signal = signal_df['Signal'].values\n",
    "        signal_label_dataset.append((signal, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967f72d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:59:10.644561Z",
     "start_time": "2025-06-05T15:59:10.625739Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EKGDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data  # list of (signal, label) tuples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        signal, label = self.data[idx]\n",
    "        \n",
    "        # Normalize signal per sample: zero mean, unit variance\n",
    "        mean = signal.mean()\n",
    "        std = signal.std()\n",
    "        normalized_signal = (signal - mean) / std\n",
    "        \n",
    "        # Convert to float32 tensor and add channel dimension\n",
    "        signal_tensor = torch.tensor(signal, dtype=torch.float32).unsqueeze(-1)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "        return signal_tensor, label_tensor\n",
    "    \n",
    "signal_label_dataset = []\n",
    "for kg, signal_df in dfs:\n",
    "    if kg in kg_to_label:\n",
    "        label = kg_to_label[kg]\n",
    "        signal = signal_df['Signal'].values[-756:]  # take last 756 elements\n",
    "        signal_label_dataset.append((signal, label))\n",
    "\n",
    "ekg_dataset = EKGDataset(signal_label_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a94af7a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:59:10.799167Z",
     "start_time": "2025-06-05T15:59:10.785963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0078],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0078],\n",
      "        [ 0.0156]]) torch.Size([756, 1]) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "sample_x, sample_y = ekg_dataset.__getitem__(0)\n",
    "print(sample_x[:5], sample_x.shape, sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2809706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T16:00:26.981571Z",
     "start_time": "2025-06-05T15:59:10.980926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.6799\n",
      "Epoch 2/30, Loss: 0.6752\n",
      "Epoch 3/30, Loss: 0.6712\n",
      "Epoch 4/30, Loss: 0.6678\n",
      "Epoch 5/30, Loss: 0.6651\n",
      "Validation Loss: 0.6904, Accuracy: 0.5556\n",
      "Epoch 6/30, Loss: 0.6630\n",
      "Epoch 7/30, Loss: 0.6617\n",
      "Epoch 8/30, Loss: 0.6613\n",
      "Epoch 9/30, Loss: 0.6618\n",
      "Epoch 10/30, Loss: 0.6626\n",
      "Validation Loss: 0.7079, Accuracy: 0.5556\n",
      "Epoch 11/30, Loss: 0.6631\n",
      "Epoch 12/30, Loss: 0.6630\n",
      "Epoch 13/30, Loss: 0.6625\n",
      "Epoch 14/30, Loss: 0.6619\n",
      "Epoch 15/30, Loss: 0.6613\n",
      "Validation Loss: 0.6994, Accuracy: 0.5556\n",
      "Epoch 16/30, Loss: 0.6610\n",
      "Epoch 17/30, Loss: 0.6608\n",
      "Epoch 18/30, Loss: 0.6607\n",
      "Epoch 19/30, Loss: 0.6607\n",
      "Epoch 20/30, Loss: 0.6607\n",
      "Validation Loss: 0.6933, Accuracy: 0.5556\n",
      "Epoch 21/30, Loss: 0.6608\n",
      "Epoch 22/30, Loss: 0.6608\n",
      "Epoch 23/30, Loss: 0.6607\n",
      "Epoch 24/30, Loss: 0.6607\n",
      "Epoch 25/30, Loss: 0.6605\n",
      "Validation Loss: 0.6928, Accuracy: 0.5556\n",
      "Epoch 26/30, Loss: 0.6604\n",
      "Epoch 27/30, Loss: 0.6602\n",
      "Epoch 28/30, Loss: 0.6600\n",
      "Epoch 29/30, Loss: 0.6597\n",
      "Epoch 30/30, Loss: 0.6595\n",
      "Validation Loss: 0.6958, Accuracy: 0.5556\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple RNN model\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, output_size=1):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]  # Take the last output\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = SimpleRNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_size = int(0.8 * len(ekg_dataset))\n",
    "val_size = len(ekg_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(ekg_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for signals, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(signals)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.eval()\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in val_loader:\n",
    "                outputs = model(signals)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6423e2e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T16:02:59.299795Z",
     "start_time": "2025-06-05T16:00:26.984579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.6923\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 2/30, Loss: 0.6878\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 3/30, Loss: 0.6838\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 4/30, Loss: 0.6803\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 5/30, Loss: 0.6773\n",
      "Train Accuracy: 0.6250\n",
      "Validation Loss: 0.6872, Accuracy: 0.5556\n",
      "Epoch 6/30, Loss: 0.6746\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 7/30, Loss: 0.6720\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 8/30, Loss: 0.6694\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 9/30, Loss: 0.6669\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 10/30, Loss: 0.6646\n",
      "Train Accuracy: 0.6250\n",
      "Validation Loss: 0.6909, Accuracy: 0.5556\n",
      "Epoch 11/30, Loss: 0.6627\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 12/30, Loss: 0.6614\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 13/30, Loss: 0.6614\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 14/30, Loss: 0.6626\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 15/30, Loss: 0.6635\n",
      "Train Accuracy: 0.6250\n",
      "Validation Loss: 0.7093, Accuracy: 0.5556\n",
      "Epoch 16/30, Loss: 0.6632\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 17/30, Loss: 0.6622\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 18/30, Loss: 0.6613\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 19/30, Loss: 0.6607\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 20/30, Loss: 0.6604\n",
      "Train Accuracy: 0.6250\n",
      "Validation Loss: 0.6952, Accuracy: 0.5556\n",
      "Epoch 21/30, Loss: 0.6604\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 22/30, Loss: 0.6604\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 23/30, Loss: 0.6605\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 24/30, Loss: 0.6606\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 25/30, Loss: 0.6605\n",
      "Train Accuracy: 0.6250\n",
      "Validation Loss: 0.6920, Accuracy: 0.5556\n",
      "Epoch 26/30, Loss: 0.6604\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 27/30, Loss: 0.6602\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 28/30, Loss: 0.6600\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 29/30, Loss: 0.6597\n",
      "Train Accuracy: 0.6250\n",
      "Epoch 30/30, Loss: 0.6594\n",
      "Train Accuracy: 0.6250\n",
      "Validation Loss: 0.6947, Accuracy: 0.5556\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple GRU model\n",
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=128, output_size=1):\n",
    "        super(SimpleGRU, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = out[:, -1, :]  # Take the last output\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "gru_model = SimpleGRU()\n",
    "optimizer = torch.optim.Adam(gru_model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    gru_model.train()\n",
    "    total_loss = 0\n",
    "    for signals, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = gru_model(signals)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "    # Calculate train accuracy\n",
    "    gru_model.eval()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    with torch.no_grad():\n",
    "        for signals, labels in train_loader:\n",
    "            outputs = gru_model(signals)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "    train_accuracy = train_correct / train_total\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        gru_model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in val_loader:\n",
    "                outputs = gru_model(signals)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141104fe9523522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
